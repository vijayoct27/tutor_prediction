{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import stats\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet') \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "st = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(bio):\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"one\", \"two\", \"new\", \"previously\", \"shown\", 'math']\n",
    "    stop_words = stop_words.union(new_words)\n",
    "\n",
    "    #Remove punctuations\n",
    "    text = re.sub('[^a-zA-Z]', ' ', bio)\n",
    "    \n",
    "    #Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    # remove periods\n",
    "    text = text.replace('.', '').replace(',' , '')\n",
    "    \n",
    "    #Convert to list from string\n",
    "    text = text.split()\n",
    "    \n",
    "    ##Stemming\n",
    "    stemmer=PorterStemmer()\n",
    "    #Lemmatisation\n",
    "    lem = WordNetLemmatizer()\n",
    "    #text = [stemmer.stem(lem.lemmatize(word)) for word in text if not word in stop_words]\n",
    "    text = [lem.lemmatize(word) for word in text if not word in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('ok, then')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_list = ['experience teaching tutoring', 'experience tutoring student', 'experience working student', \n",
    "                   'many student', 'many year', \n",
    "                   'year experience teaching', 'year experience tutoring',\n",
    "                   'year experience working',\n",
    "                   'year teaching experience', 'year tutoring experience']\n",
    "                   \n",
    "welcoming_list = ['look forward hearing', 'look forward helping', 'look forward meeting', 'look forward working',\n",
    "                  'forward working', 'hello name', 'hi name', 'please contact', 'please feel',\n",
    "                  'would like', 'would love', 'feel free contact', 'feel free reach', 'free contact question']\n",
    "                  \n",
    "goal_list = ['goal help student', 'achieve academic goal',  \n",
    "             'help student succeed', 'helping student achieve']\n",
    "\n",
    "passion_list = ['enjoy helping student', 'enjoy working student', 'look forward', \n",
    "                 'believe every student', 'love help', 'love teaching', \n",
    "                 'love helping student', 'love working student', 'would love help']\n",
    "\n",
    "experience_array = []\n",
    "welcoming_array = []\n",
    "goal_array = []\n",
    "passion_array = []\n",
    "for b in corpus:\n",
    "    experience_count = 0\n",
    "    welcoming_count = 0\n",
    "    goal_count = 0\n",
    "    passion_count = 0\n",
    "    if any(x in b for x in experience_list):\n",
    "        experience_count += 1\n",
    "    if any(x in b for x in welcoming_list):\n",
    "        welcoming_count += 1\n",
    "    if any(x in b for x in goal_list):\n",
    "        goal_count += 1\n",
    "    if any(x in b for x in passion_list):\n",
    "        passion_count += 1\n",
    "    experience_array.append(experience_count)\n",
    "    welcoming_array.append(welcoming_count)\n",
    "    goal_array.append(goal_count)\n",
    "    passion_array.append(passion_count)\n",
    "df_eng['experience_kw'] = np.array(experience_array)\n",
    "df_eng['welcoming_kw'] = np.array(welcoming_array)\n",
    "df_eng['goal_kw'] = np.array(goal_array)\n",
    "df_eng['passion_kw'] = np.array(passion_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_subjects = ['Prealgebra',\n",
    " 'Algebra 1',\n",
    " 'Geometry',\n",
    " 'Algebra 2',\n",
    " 'Elementary Math',\n",
    " 'Trigonometry',\n",
    " 'Precalculus',\n",
    " 'SAT Math',\n",
    " 'ACT Math',\n",
    " 'Grammar',\n",
    " 'Vocabulary',\n",
    " 'Calculus',\n",
    " 'Elementary Science',\n",
    " 'GED',\n",
    " 'Reading',\n",
    " 'English',\n",
    " 'Proofreading',\n",
    " 'Probability',\n",
    " 'GRE',\n",
    " 'Spelling',\n",
    " 'Writing',\n",
    " 'PSAT',\n",
    " 'ACT Science',\n",
    " 'ACT English',\n",
    " 'Biology',\n",
    " 'Physical Science',\n",
    " 'Microsoft Word',\n",
    " 'Statistics',\n",
    " 'Microsoft Excel',\n",
    " 'SAT Reading',\n",
    " 'Chemistry',\n",
    " 'SAT Writing',\n",
    " 'ACT Reading',\n",
    " 'Physics',\n",
    " 'American History']\n",
    "\n",
    "full_subjects_list = ['Prealgebra',\n",
    " 'Algebra 1',\n",
    " 'Geometry',\n",
    " 'Algebra 2',\n",
    " 'Elementary Math',\n",
    " 'Trigonometry',\n",
    " 'Precalculus',\n",
    " 'SAT Math',\n",
    " 'ACT Math',\n",
    " 'Grammar',\n",
    " 'Vocabulary',\n",
    " 'Calculus',\n",
    " 'Elementary Science',\n",
    " 'GED',\n",
    " 'Reading',\n",
    " 'English',\n",
    " 'Proofreading',\n",
    " 'Probability',\n",
    " 'GRE',\n",
    " 'Spelling',\n",
    " 'Writing',\n",
    " 'PSAT',\n",
    " 'ACT Science',\n",
    " 'ACT English',\n",
    " 'Biology',\n",
    " 'Physical Science',\n",
    " 'Microsoft Word',\n",
    " 'Statistics',\n",
    " 'Microsoft Excel',\n",
    " 'SAT Reading',\n",
    " 'Chemistry',\n",
    " 'SAT Writing',\n",
    " 'ACT Reading',\n",
    " 'Physics',\n",
    " 'American History',\n",
    " 'Microsoft PowerPoint',\n",
    " 'ASVAB',\n",
    " 'Literature',\n",
    " 'General Computer',\n",
    " 'ESL/ESOL',\n",
    " 'Geography',\n",
    " 'TOEFL',\n",
    " 'GMAT',\n",
    " 'World History',\n",
    " 'SSAT',\n",
    " 'Anatomy',\n",
    " 'Psychology',\n",
    " 'Government & Politics',\n",
    " 'Spanish',\n",
    " 'European History',\n",
    " 'Physiology',\n",
    " 'Study Skills',\n",
    " 'Astronomy',\n",
    " 'Microeconomics',\n",
    " 'Ecology',\n",
    " 'HTML',\n",
    " 'Macroeconomics',\n",
    " 'Philosophy',\n",
    " 'Java',\n",
    " 'Music Theory',\n",
    " 'Microbiology',\n",
    " 'Biochemistry',\n",
    " 'Linear Algebra',\n",
    " 'Social Studies',\n",
    " 'Phonics',\n",
    " 'Financial Accounting',\n",
    " 'Managerial Accounting',\n",
    " 'Finance',\n",
    " 'Differential Equations',\n",
    " 'Geology',\n",
    " 'Computer Programming',\n",
    " 'SQL',\n",
    " 'Python',\n",
    " 'LSAT',\n",
    " 'SPSS',\n",
    " 'French',\n",
    " 'Handwriting',\n",
    " 'Nursing',\n",
    " 'Political Science',\n",
    " 'Adobe Photoshop',\n",
    " 'JavaScript',\n",
    " 'Art History',\n",
    " 'German',\n",
    " 'C',\n",
    " 'Law',\n",
    " 'Latin',\n",
    " 'Adobe Illustrator',\n",
    " 'R',\n",
    " 'Art Theory',\n",
    " 'Chinese',\n",
    " 'Italian',\n",
    " 'Japanese',\n",
    " 'Portuguese',\n",
    " 'NCLEX',\n",
    " 'Discrete Math',\n",
    " 'Romanian',\n",
    " 'Elementary (K-6th)',\n",
    " 'Organic Chemistry',\n",
    " 'TAKS',\n",
    " 'Business',\n",
    " 'Public Speaking',\n",
    " 'Special Needs',\n",
    " 'Biostatistics',\n",
    " 'Macintosh',\n",
    " 'Praxis',\n",
    " 'Russian',\n",
    " 'Computer Science',\n",
    " 'Track & Field']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_list = []\n",
    "mid_list = []\n",
    "unpopular_list = []\n",
    "for f in df_eng[feature]:\n",
    "    num_popular = 0\n",
    "    num_mid = 0\n",
    "    num_unpopular = 0\n",
    "    for j in f:\n",
    "        if j in popular_subjects:\n",
    "            num_popular += 1\n",
    "        elif j in mid_subjects:\n",
    "            num_mid += 1\n",
    "        elif j in unpopular_subjects:\n",
    "            num_unpopular += 1\n",
    "    popular_list.append(num_popular)\n",
    "    mid_list.append(num_mid)\n",
    "    unpopular_list.append(num_unpopular)\n",
    "    \n",
    "df_eng['num_popular_subjects'] = np.array(popular_list)\n",
    "df_eng['num_mid_subjects'] = np.array(mid_list)\n",
    "df_eng['num_unpopular_subjects'] = np.array(unpopular_list)\n",
    "\n",
    "# engineer edu degree categories\n",
    "\n",
    "undergrad = ['BA', 'B.A.', 'BS', 'B.S.', '']\n",
    "postgrad = ['MS', 'M.S', 'MA', 'M.A', 'masters', 'Masters', 'CA', 'C.A', \n",
    "            'MBA', 'M.B.A', 'MD', 'M.D', 'PhD', 'Ph.D', 'Ph.D.', 'Graduate']\n",
    "certified = ['education', 'Ced', 'certified']\n",
    "\n",
    "undergrad_degree = []\n",
    "postgrad_degree = []\n",
    "certified_degree = []\n",
    "for e in df_eng['edu']:\n",
    "    undergrad_count = 0\n",
    "    postgrad_count = 0\n",
    "    certified_count = 0\n",
    "    if any(x in e for x in undergrad):\n",
    "        undergrad_count += 1\n",
    "    if any(x in e for x in postgrad):\n",
    "        postgrad_count += 1\n",
    "    if any(x in e for x in certified):\n",
    "        certified_count +=1\n",
    "    undergrad_degree.append(undergrad_count)\n",
    "    postgrad_degree.append(postgrad_count)\n",
    "    certified_degree.append(certified_count)\n",
    "df_eng['undergrad_degree'] = np.array(undergrad_degree)\n",
    "df_eng['postgrad_degree'] = np.array(postgrad_degree)\n",
    "df_eng['certified_degree'] = np.array(certified_degree)\n",
    "\n",
    "# get university rankings\n",
    "df_wur = pd.read_csv('world-university-rankings_cwurData.csv')\n",
    "df_wur_select = df_wur[['institution', 'world_rank']]\n",
    "\n",
    "list_of_top_schools = (list(df_wur_select['institution'][:30]) + \n",
    "['Berkeley', 'Caltech', 'Harvard', 'Yale', 'Princeton', 'MIT', 'Stanford'])\n",
    "\n",
    "top_school = []\n",
    "for e in df_eng['edu']:\n",
    "    top = 0\n",
    "    if any(x in e for x in list_of_top_schools):\n",
    "        top += 1\n",
    "    top_school.append(top)\n",
    "df_eng['top_school'] = np.array(top_school)\n",
    "\n",
    "df_eng['bio_count'] = df_eng['bio'].apply(lambda x: len(str(x).split(\" \")))\n",
    "df_eng['desc_count'] = df_eng['descriptions'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
